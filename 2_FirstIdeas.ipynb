{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50769992",
   "metadata": {},
   "source": [
    "# Motor Imagery EEG-BCIs - 0 to Deep Learning with BCI-IV 2a dataset\n",
    "\n",
    "@author: João Araújo ([LinkedIn](https://www.linkedin.com/in/joao-araujo-60470193/))\n",
    "\n",
    "## 2 - Initial Modelling Ideas: channel-based, PCA and CSP\n",
    "When trying to model EEG data for classification, we need to think what types of features contain discriminative information and what models can be chosen to make the best use of such information. Here, we will start by exploring initial feature engineering ideas one might have when dealing with EEG data, namely:\n",
    "\n",
    "- Using a summary statistic of each channel data as our main set of features\n",
    "- Deriving features from spatial filters using unsupervised methods (PCA)\n",
    "- Deriving features from spatial filters using supervised methods (CSP)\n",
    "\n",
    "We will also introduce the idea of model validation for EEG data - a process we must use to make sure our models do not overfit - while making sure we do not \"leak\" test data into the training including on the feature estimation stage. Let's start by setting up our initial variables and defining our main imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6ce5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Load our previous dataset\n",
    "X = loadmat('BCI_IV_2a.mat')\n",
    "# Define our variables of interest\n",
    "M_res = X['M_res']\n",
    "subj_labels = X['subj_labels']\n",
    "class_labels = np.squeeze(X['class_labels'])\n",
    "\n",
    "# Get our channel names list with the help of our description file\n",
    "ch_names     = list(np.arange(1,23))\n",
    "ch_names[0]  = 'Fz (1)'\n",
    "ch_names[7]  = 'C3 (8)'\n",
    "ch_names[9]  = 'Cz (10)'\n",
    "ch_names[11] = 'C4 (12)'\n",
    "ch_names[19] = 'Pz (20)'\n",
    "\n",
    "# delete our loaded mat object\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf84d1f",
   "metadata": {},
   "source": [
    "### Channels as features\n",
    "Here, we assume that EEG channels can individually hold the right information for classification as they are, without further transformations other than getting a summary statistic that captures the behaviour of each channel. For this example, let's say that summary statistic is variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771bdfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance as the summary statistic of our signal to use as feature\n",
    "X = np.var(M_res, axis = 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39b31e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">This leaves us with a more tabular dataset, with each channel being represented by one feature value - we eliminated the time-varying component of the dataset. Now we can think about fitting a model which will allow us to separate the 4 motor imagery conditions across subjects. \n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: justify\">However, we need to test this model using a <strong>validation</strong> method. Ideally, we want this model to be able to generalize across different participants - so we need to account for inter-subject variance. For that, we should train our model using data from a few subjects and test the model on data from other subjects. As this is a small dataset (9 subjects), we can train the data on 8 subjects and test the model on the remaining subject and do this 9 times so the model gets tested on data from all participants. We can call it <strong>Leave-One-Participant-Out Cross-Validation</strong>:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e079cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to perform One-Subject-Out Cross-Validation \n",
    "\n",
    "def validateSimpleModels(subj_labels,X,model):\n",
    "    # Get our list of unique subjects to \n",
    "    unique_subjects = np.unique(subj_labels)\n",
    "    \n",
    "    # Initialize our list of test accuracy scores for every subject \n",
    "    test_scores = []\n",
    "    \n",
    "    # Perfrom cross-validation leaving always a different subject out\n",
    "    for subject in unique_subjects:\n",
    "        \n",
    "        # Get training data and labels\n",
    "        X_train = X[subj_labels != subject,:]\n",
    "        y_train = class_labels[subj_labels != subject]\n",
    "        \n",
    "        # Fit model\n",
    "        classifier = clone(model) # Clone model to reset it for every fold\n",
    "        classifier.fit(X_train,y_train)\n",
    "        \n",
    "        # Get training accuracy\n",
    "        train_fit = classifier.score(X_train,y_train)\n",
    "        \n",
    "        # Get test data (subject that we left out) and MI class labels\n",
    "        X_test  = X[subj_labels == subject,:]\n",
    "        y_test  = class_labels[subj_labels == subject]\n",
    "        \n",
    "        # Get accuracy\n",
    "        test_fit = classifier.score(X_test,y_test)\n",
    "        # Append score to our test scores\n",
    "        test_scores.append(test_fit)\n",
    "\n",
    "        print('Subject ' +str(subject)[:4]+' test acc: ' +str(test_fit)[:4]+ ' (train score: '+str(train_fit)[:4]+')')\n",
    "    \n",
    "    print('Average model accuracy: '+str(np.mean(test_scores))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e655e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Now we can think of a model. We might hypothesize that a weighted combination of these channel variances will give us enough information to distinguish MI classes. Or we can hypothesize that our data is not linearly separable and we need to project this data into a non-linear space before separation. Let's test the two hypotheses and fit both a linear (logistic regression) and non-linear (SVM with radial-basis function) classifier on our features and see our results:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cc4db88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject A01 test acc: 0.38 (train score: 0.42)\n",
      "Subject A02 test acc: 0.29 (train score: 0.44)\n",
      "Subject A03 test acc: 0.44 (train score: 0.41)\n",
      "Subject A04 test acc: 0.33 (train score: 0.43)\n",
      "Subject A05 test acc: 0.23 (train score: 0.44)\n",
      "Subject A06 test acc: 0.27 (train score: 0.43)\n",
      "Subject A07 test acc: 0.27 (train score: 0.43)\n",
      "Subject A08 test acc: 0.42 (train score: 0.40)\n",
      "Subject A09 test acc: 0.40 (train score: 0.40)\n",
      "Average model accuracy: 0.34\n",
      "Subject A01 test acc: 0.35 (train score: 0.55)\n",
      "Subject A02 test acc: 0.24 (train score: 0.57)\n",
      "Subject A03 test acc: 0.36 (train score: 0.53)\n",
      "Subject A04 test acc: 0.27 (train score: 0.56)\n",
      "Subject A05 test acc: 0.25 (train score: 0.57)\n",
      "Subject A06 test acc: 0.26 (train score: 0.54)\n",
      "Subject A07 test acc: 0.26 (train score: 0.57)\n",
      "Subject A08 test acc: 0.36 (train score: 0.53)\n",
      "Subject A09 test acc: 0.35 (train score: 0.53)\n",
      "Average model accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Quickly define some models\n",
    "classifier_linear = LogisticRegression(random_state = 0,\n",
    "                                penalty = 'l2',\n",
    "                                C = 100,\n",
    "                                max_iter = 5000,\n",
    "                                multi_class = 'multinomial') \n",
    "\n",
    "classifier_svm = SVC(kernel = 'rbf', \n",
    "                     C = 100)\n",
    "\n",
    "# See which one is best using our newly created function\n",
    "validateSimpleModels(subj_labels,X,classifier_linear)\n",
    "validateSimpleModels(subj_labels,X,classifier_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1636cd2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Analysing these accuracies, we can see that both models already work above chance level for most subjects. Interestingly we can see that the non-linear model, despite showing better training accuracies, does not show better test accuracies in a typical case of <em>overfitting<\\em>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59d3a3",
   "metadata": {},
   "source": [
    "### Introducing Spatial Filtering: PCA\n",
    "<div style=\"text-align: justify\">One next idea we can test concerns spatial filtering. Conceptually, we may think that creating new features by weighted combiniations of different channels may help in uncovering discriminant patterns of information. An unsupervised way of doing this is through PCA. When using PCA, we hypothesize that combinations of channels explaining different sources of uncorrelated variance will be also important features to distinguish MI classes. Let's implement our own custom PCA step-by-step to better understand what we are doing:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf67f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# Calculate PCA giving each subject the same weight (regardless of number of trials they have)\n",
    "def myPCA(M_res,subj_labels):\n",
    "    \n",
    "    # Get our list of unique subjects \n",
    "    unique_subjects = np.unique(subj_labels)\n",
    "    \n",
    "    # Initialize our subject-weighted covariance\n",
    "    Cov_subj = np.zeros((M_res.shape[1],M_res.shape[1]))\n",
    "    \n",
    "    # Iterate through every subject and get their channel covariance matrix\n",
    "    for subject in unique_subjects:\n",
    "        Data_subj = M_res[subj_labels == subject,:,:].swapaxes(1,2).reshape(-1,M_res.shape[1])\n",
    "        Cov_subj += np.cov(Data_subj.T)\n",
    "    \n",
    "    # OPTIONAL: Compute the covariance without weighing the subjects\n",
    "    #           Since this is a balanced dataset, the differences are\n",
    "    #           minimal\n",
    "    #Cov_subj = np.cov(M_res.swapaxes(1,2).reshape(-1,M_res.shape[1]).T)\n",
    "    \n",
    "    # Perform eigendecomposition to get the sorted eigenvalues and respective eigenvectors (PCs)\n",
    "    evalues, evectors = eig(Cov_subj)\n",
    "    \n",
    "    # Return them\n",
    "    return evalues,evectors\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9b849",
   "metadata": {},
   "source": [
    "Once we apply PCA to our dataset, we can also evaluate the percentage of variance every single principal component explains and use that information to pick the PCs that will make it to our final feature space. As we will only select a fraction of these, you can also used this method to find a compressed representation of bigger EEG datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ef8c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get our unique subject list\n",
    "unique_subjects = np.unique(subj_labels)\n",
    "\n",
    "# Get our PCs (covariance eigenvectors)\n",
    "evalues, evectors = myPCA(M_res,subj_labels)\n",
    "\n",
    "# Calculate explained variance for every component\n",
    "var_exp = evalues / np.sum(evalues)\n",
    "\n",
    "# Scree plot\n",
    "plt.plot(np.arange(1,len(var_exp)+1),var_exp,'k')\n",
    "plt.plot(np.arange(1,len(var_exp)+1),var_exp,'.k')\n",
    "plt.xlabel('#Component')\n",
    "plt.ylabel('Proportional Variance Explained')\n",
    "plt.title('Scree Plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d86f0",
   "metadata": {},
   "source": [
    "We can observe the following:\n",
    "- The first component explains almost 80% of the total variance of the dataset;\n",
    "- After the first 3 PC's, all other components explain similarly low variances.\n",
    "\n",
    "In fact, let's see how much variance is explained on the first 3 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c37c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9508848479854393\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(var_exp[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a46045",
   "metadata": {},
   "source": [
    "Our 3 most relevant components keep over 95% of the dataset variance! Let's take a look to the most important channels of these components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d774dc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9ff00_row0_col0 {\n",
       "  background-color: #5d5d5d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col1, #T_9ff00_row0_col5, #T_9ff00_row1_col6, #T_9ff00_row1_col7, #T_9ff00_row1_col8, #T_9ff00_row1_col10, #T_9ff00_row1_col11, #T_9ff00_row1_col12, #T_9ff00_row1_col13, #T_9ff00_row1_col14, #T_9ff00_row1_col16, #T_9ff00_row1_col17, #T_9ff00_row2_col0, #T_9ff00_row2_col2, #T_9ff00_row2_col3, #T_9ff00_row2_col4, #T_9ff00_row2_col9, #T_9ff00_row2_col15, #T_9ff00_row2_col18, #T_9ff00_row2_col19, #T_9ff00_row2_col20, #T_9ff00_row2_col21 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col2 {\n",
       "  background-color: #9a9a9a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col3 {\n",
       "  background-color: #989898;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col4 {\n",
       "  background-color: #bebebe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9ff00_row0_col6, #T_9ff00_row0_col18 {\n",
       "  background-color: #3c3c3c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col7 {\n",
       "  background-color: #4f4f4f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col8, #T_9ff00_row0_col9, #T_9ff00_row0_col10, #T_9ff00_row0_col14, #T_9ff00_row0_col15, #T_9ff00_row0_col16, #T_9ff00_row1_col0, #T_9ff00_row1_col1, #T_9ff00_row1_col2, #T_9ff00_row1_col3, #T_9ff00_row1_col4, #T_9ff00_row1_col5, #T_9ff00_row1_col18, #T_9ff00_row1_col19, #T_9ff00_row1_col20, #T_9ff00_row1_col21, #T_9ff00_row2_col6, #T_9ff00_row2_col7, #T_9ff00_row2_col11, #T_9ff00_row2_col12, #T_9ff00_row2_col13, #T_9ff00_row2_col17 {\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9ff00_row0_col11 {\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col12 {\n",
       "  background-color: #424242;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col13 {\n",
       "  background-color: #363636;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col17 {\n",
       "  background-color: #505050;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col19 {\n",
       "  background-color: #888888;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col20, #T_9ff00_row2_col10 {\n",
       "  background-color: #636363;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row0_col21 {\n",
       "  background-color: #373737;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row1_col9 {\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row1_col15 {\n",
       "  background-color: #474747;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row2_col1 {\n",
       "  background-color: #ababab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_9ff00_row2_col5 {\n",
       "  background-color: #b3b3b3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9ff00_row2_col8 {\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9ff00_row2_col14 {\n",
       "  background-color: #c3c3c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9ff00_row2_col16 {\n",
       "  background-color: #595959;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9ff00\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9ff00_level0_col0\" class=\"col_heading level0 col0\" >Fz (1)</th>\n",
       "      <th id=\"T_9ff00_level0_col1\" class=\"col_heading level0 col1\" >2</th>\n",
       "      <th id=\"T_9ff00_level0_col2\" class=\"col_heading level0 col2\" >3</th>\n",
       "      <th id=\"T_9ff00_level0_col3\" class=\"col_heading level0 col3\" >4</th>\n",
       "      <th id=\"T_9ff00_level0_col4\" class=\"col_heading level0 col4\" >5</th>\n",
       "      <th id=\"T_9ff00_level0_col5\" class=\"col_heading level0 col5\" >6</th>\n",
       "      <th id=\"T_9ff00_level0_col6\" class=\"col_heading level0 col6\" >7</th>\n",
       "      <th id=\"T_9ff00_level0_col7\" class=\"col_heading level0 col7\" >C3 (8)</th>\n",
       "      <th id=\"T_9ff00_level0_col8\" class=\"col_heading level0 col8\" >9</th>\n",
       "      <th id=\"T_9ff00_level0_col9\" class=\"col_heading level0 col9\" >Cz (10)</th>\n",
       "      <th id=\"T_9ff00_level0_col10\" class=\"col_heading level0 col10\" >11</th>\n",
       "      <th id=\"T_9ff00_level0_col11\" class=\"col_heading level0 col11\" >C4 (12)</th>\n",
       "      <th id=\"T_9ff00_level0_col12\" class=\"col_heading level0 col12\" >13</th>\n",
       "      <th id=\"T_9ff00_level0_col13\" class=\"col_heading level0 col13\" >14</th>\n",
       "      <th id=\"T_9ff00_level0_col14\" class=\"col_heading level0 col14\" >15</th>\n",
       "      <th id=\"T_9ff00_level0_col15\" class=\"col_heading level0 col15\" >16</th>\n",
       "      <th id=\"T_9ff00_level0_col16\" class=\"col_heading level0 col16\" >17</th>\n",
       "      <th id=\"T_9ff00_level0_col17\" class=\"col_heading level0 col17\" >18</th>\n",
       "      <th id=\"T_9ff00_level0_col18\" class=\"col_heading level0 col18\" >19</th>\n",
       "      <th id=\"T_9ff00_level0_col19\" class=\"col_heading level0 col19\" >Pz (20)</th>\n",
       "      <th id=\"T_9ff00_level0_col20\" class=\"col_heading level0 col20\" >21</th>\n",
       "      <th id=\"T_9ff00_level0_col21\" class=\"col_heading level0 col21\" >22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Components</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "      <th class=\"blank col16\" >&nbsp;</th>\n",
       "      <th class=\"blank col17\" >&nbsp;</th>\n",
       "      <th class=\"blank col18\" >&nbsp;</th>\n",
       "      <th class=\"blank col19\" >&nbsp;</th>\n",
       "      <th class=\"blank col20\" >&nbsp;</th>\n",
       "      <th class=\"blank col21\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9ff00_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_9ff00_row0_col0\" class=\"data row0 col0\" >0.039609</td>\n",
       "      <td id=\"T_9ff00_row0_col1\" class=\"data row0 col1\" >0.036409</td>\n",
       "      <td id=\"T_9ff00_row0_col2\" class=\"data row0 col2\" >0.045973</td>\n",
       "      <td id=\"T_9ff00_row0_col3\" class=\"data row0 col3\" >0.050010</td>\n",
       "      <td id=\"T_9ff00_row0_col4\" class=\"data row0 col4\" >0.049010</td>\n",
       "      <td id=\"T_9ff00_row0_col5\" class=\"data row0 col5\" >0.043598</td>\n",
       "      <td id=\"T_9ff00_row0_col6\" class=\"data row0 col6\" >0.021333</td>\n",
       "      <td id=\"T_9ff00_row0_col7\" class=\"data row0 col7\" >0.037620</td>\n",
       "      <td id=\"T_9ff00_row0_col8\" class=\"data row0 col8\" >0.049619</td>\n",
       "      <td id=\"T_9ff00_row0_col9\" class=\"data row0 col9\" >0.056353</td>\n",
       "      <td id=\"T_9ff00_row0_col10\" class=\"data row0 col10\" >0.054552</td>\n",
       "      <td id=\"T_9ff00_row0_col11\" class=\"data row0 col11\" >0.048088</td>\n",
       "      <td id=\"T_9ff00_row0_col12\" class=\"data row0 col12\" >0.034153</td>\n",
       "      <td id=\"T_9ff00_row0_col13\" class=\"data row0 col13\" >0.038734</td>\n",
       "      <td id=\"T_9ff00_row0_col14\" class=\"data row0 col14\" >0.049767</td>\n",
       "      <td id=\"T_9ff00_row0_col15\" class=\"data row0 col15\" >0.056078</td>\n",
       "      <td id=\"T_9ff00_row0_col16\" class=\"data row0 col16\" >0.055404</td>\n",
       "      <td id=\"T_9ff00_row0_col17\" class=\"data row0 col17\" >0.050056</td>\n",
       "      <td id=\"T_9ff00_row0_col18\" class=\"data row0 col18\" >0.043924</td>\n",
       "      <td id=\"T_9ff00_row0_col19\" class=\"data row0 col19\" >0.051599</td>\n",
       "      <td id=\"T_9ff00_row0_col20\" class=\"data row0 col20\" >0.049286</td>\n",
       "      <td id=\"T_9ff00_row0_col21\" class=\"data row0 col21\" >0.038825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9ff00_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_9ff00_row1_col0\" class=\"data row1 col0\" >0.108346</td>\n",
       "      <td id=\"T_9ff00_row1_col1\" class=\"data row1 col1\" >0.050285</td>\n",
       "      <td id=\"T_9ff00_row1_col2\" class=\"data row1 col2\" >0.064181</td>\n",
       "      <td id=\"T_9ff00_row1_col3\" class=\"data row1 col3\" >0.083702</td>\n",
       "      <td id=\"T_9ff00_row1_col4\" class=\"data row1 col4\" >0.061411</td>\n",
       "      <td id=\"T_9ff00_row1_col5\" class=\"data row1 col5\" >0.047578</td>\n",
       "      <td id=\"T_9ff00_row1_col6\" class=\"data row1 col6\" >0.002653</td>\n",
       "      <td id=\"T_9ff00_row1_col7\" class=\"data row1 col7\" >0.004285</td>\n",
       "      <td id=\"T_9ff00_row1_col8\" class=\"data row1 col8\" >0.007671</td>\n",
       "      <td id=\"T_9ff00_row1_col9\" class=\"data row1 col9\" >0.011851</td>\n",
       "      <td id=\"T_9ff00_row1_col10\" class=\"data row1 col10\" >0.006781</td>\n",
       "      <td id=\"T_9ff00_row1_col11\" class=\"data row1 col11\" >0.002375</td>\n",
       "      <td id=\"T_9ff00_row1_col12\" class=\"data row1 col12\" >0.000670</td>\n",
       "      <td id=\"T_9ff00_row1_col13\" class=\"data row1 col13\" >0.016238</td>\n",
       "      <td id=\"T_9ff00_row1_col14\" class=\"data row1 col14\" >0.013510</td>\n",
       "      <td id=\"T_9ff00_row1_col15\" class=\"data row1 col15\" >0.016503</td>\n",
       "      <td id=\"T_9ff00_row1_col16\" class=\"data row1 col16\" >0.015253</td>\n",
       "      <td id=\"T_9ff00_row1_col17\" class=\"data row1 col17\" >0.016908</td>\n",
       "      <td id=\"T_9ff00_row1_col18\" class=\"data row1 col18\" >0.094402</td>\n",
       "      <td id=\"T_9ff00_row1_col19\" class=\"data row1 col19\" >0.096393</td>\n",
       "      <td id=\"T_9ff00_row1_col20\" class=\"data row1 col20\" >0.099325</td>\n",
       "      <td id=\"T_9ff00_row1_col21\" class=\"data row1 col21\" >0.179676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9ff00_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_9ff00_row2_col0\" class=\"data row2 col0\" >0.000015</td>\n",
       "      <td id=\"T_9ff00_row2_col1\" class=\"data row2 col1\" >0.045691</td>\n",
       "      <td id=\"T_9ff00_row2_col2\" class=\"data row2 col2\" >0.018167</td>\n",
       "      <td id=\"T_9ff00_row2_col3\" class=\"data row2 col3\" >0.000380</td>\n",
       "      <td id=\"T_9ff00_row2_col4\" class=\"data row2 col4\" >0.012750</td>\n",
       "      <td id=\"T_9ff00_row2_col5\" class=\"data row2 col5\" >0.046383</td>\n",
       "      <td id=\"T_9ff00_row2_col6\" class=\"data row2 col6\" >0.082211</td>\n",
       "      <td id=\"T_9ff00_row2_col7\" class=\"data row2 col7\" >0.111965</td>\n",
       "      <td id=\"T_9ff00_row2_col8\" class=\"data row2 col8\" >0.038367</td>\n",
       "      <td id=\"T_9ff00_row2_col9\" class=\"data row2 col9\" >0.001437</td>\n",
       "      <td id=\"T_9ff00_row2_col10\" class=\"data row2 col10\" >0.025376</td>\n",
       "      <td id=\"T_9ff00_row2_col11\" class=\"data row2 col11\" >0.124071</td>\n",
       "      <td id=\"T_9ff00_row2_col12\" class=\"data row2 col12\" >0.129773</td>\n",
       "      <td id=\"T_9ff00_row2_col13\" class=\"data row2 col13\" >0.122373</td>\n",
       "      <td id=\"T_9ff00_row2_col14\" class=\"data row2 col14\" >0.041155</td>\n",
       "      <td id=\"T_9ff00_row2_col15\" class=\"data row2 col15\" >0.001292</td>\n",
       "      <td id=\"T_9ff00_row2_col16\" class=\"data row2 col16\" >0.029279</td>\n",
       "      <td id=\"T_9ff00_row2_col17\" class=\"data row2 col17\" >0.122713</td>\n",
       "      <td id=\"T_9ff00_row2_col18\" class=\"data row2 col18\" >0.028250</td>\n",
       "      <td id=\"T_9ff00_row2_col19\" class=\"data row2 col19\" >0.000638</td>\n",
       "      <td id=\"T_9ff00_row2_col20\" class=\"data row2 col20\" >0.017515</td>\n",
       "      <td id=\"T_9ff00_row2_col21\" class=\"data row2 col21\" >0.000197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24b21cd3370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a table with the most important channel weights for each of the 3 most important components\n",
    "best_evals_df = pd.DataFrame(evectors[:,:3].T**2,columns = ch_names, index = [1,2,3])\n",
    "best_evals_df.index.name = 'Components'\n",
    "# Add an heatmap effect to the table for easier visualization\n",
    "best_evals_df.style.background_gradient(cmap ='gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b5353",
   "metadata": {},
   "source": [
    "Looking at this table we can describe our components as:\n",
    "- **Component 1** - A balanced average of most channels but generally stronger weights for central electrodes\n",
    "- **Component 2** - Mostly a mix of frontal and parietal channels\n",
    "- **Component 3** - Both left and right lateralized central channels\n",
    "\n",
    "Let's integrate our feature estimation via PCA on our validation algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a6692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateSimpleModels_PCA(subj_labels,M_res,model,n_pcs):\n",
    "    # Get our list of unique subjects to \n",
    "    unique_subjects = np.unique(subj_labels)\n",
    "    \n",
    "    # Initialize our list of test accuracy scores for every subject \n",
    "    test_scores = []\n",
    "    \n",
    "    # Perfrom cross-validation leaving always a different subject out\n",
    "    for subject in unique_subjects:\n",
    "        \n",
    "        # Calculate our PC's from the training dataset\n",
    "        evalues,evectors = myPCA(M_res[subj_labels != subject,:,:],subj_labels[subj_labels != subject])\n",
    "        \n",
    "        # Get our variance features from the PC-projected data (whole dataset)\n",
    "        X = np.zeros((len(subj_labels),n_pcs))\n",
    "        for i in range(M_res.shape[0]):\n",
    "            X[i,:] = np.var(M_res[i,:,:].T @ evectors[:,:n_pcs],axis = 0)\n",
    "        \n",
    "        # Get our training data and MI class labels\n",
    "        X_train = X[subj_labels != subject,:]\n",
    "        y_train = class_labels[subj_labels != subject]\n",
    "        \n",
    "        # Fit our model to the training data\n",
    "        classifier = clone(model)\n",
    "        classifier.fit(X_train,y_train)\n",
    "        \n",
    "        # Get training accuracy (training fit)\n",
    "        train_fit = classifier.score(X_train,y_train)\n",
    "        \n",
    "        # Get test data and labels\n",
    "        X_test  = X[subj_labels == subject,:]\n",
    "        y_test  = class_labels[subj_labels == subject]\n",
    "        \n",
    "        # Get test accuracy\n",
    "        test_fit = classifier.score(X_test,y_test)\n",
    "        # Append it to our test score list\n",
    "        test_scores.append(test_fit)\n",
    "\n",
    "        print('Subject ' +str(subject)[:4]+' test acc: ' +str(test_fit)[:4]+ ' (train score: '+str(train_fit)[:4]+')')\n",
    "    \n",
    "    print('Average model accuracy: '+str(np.mean(test_scores))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b4009",
   "metadata": {},
   "source": [
    "Let's assume a weighted sum of these spatial filters is indeed what we need for separating data. You can change the number of components to add to the model and see how it affects its classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d379cac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject A01 test acc: 0.38 (train score: 0.36)\n",
      "Subject A02 test acc: 0.25 (train score: 0.37)\n",
      "Subject A03 test acc: 0.36 (train score: 0.35)\n",
      "Subject A04 test acc: 0.28 (train score: 0.36)\n",
      "Subject A05 test acc: 0.27 (train score: 0.37)\n",
      "Subject A06 test acc: 0.23 (train score: 0.35)\n",
      "Subject A07 test acc: 0.28 (train score: 0.36)\n",
      "Subject A08 test acc: 0.30 (train score: 0.34)\n",
      "Subject A09 test acc: 0.25 (train score: 0.37)\n",
      "Average model accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Define another linear classifier for our PCA-projected dataset\n",
    "classifier_linear = LogisticRegression(random_state = 0,\n",
    "                                solver = 'liblinear',\n",
    "                                penalty = 'l2',\n",
    "                                C = 1000,\n",
    "                                max_iter = 20000) \n",
    "\n",
    "# Will it give better results than the channel-based classifier?\n",
    "n_pcs = 22\n",
    "validateSimpleModels_PCA(subj_labels,M_res,classifier_linear,n_pcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10d539",
   "metadata": {},
   "source": [
    "Unfortunately, PCA by itself did not improve our classification scores. In practice this means that building unsupervised spatial filters may not necessarily be helpful in a supervised learning task (at least by themselves). So what if we could build such filters in a supervised way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f61d1d8",
   "metadata": {},
   "source": [
    "### Introducing Spatial Filtering: CSP\n",
    "Spatial filters can also be built in a supervised way, using svd or eigendecomposition methods similar to PCA - using methods like CSP. With CSP, we aim to estimate spatial filters that maximize the variance for an MI class while minimizing for another. This means the method is inherently useful for two-class classification problems but can also be extended for multiple classes using several different methods (check the MNE [code](https://github.com/mne-tools/mne-python/blob/main/mne/decoding/csp.py)). For the demonstration purposes of this notebook, however, we will choose two MI classes (right/left hand) to show how CSP works.\n",
    "\n",
    "<div style=\"text-align: justify\"> The way CSP is normally used is by choosing a bandpass (temporal) filter that will seggregate the specific frequencies we think are useful to separate these data. Then we estimate the spatial filters. Let's start by seggregating our 2 MI classes and filtering everything other than alpha and beta (SMR) bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26131d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for filter\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "\n",
    "# define bandpass filter\n",
    "filter_order = 4\n",
    "fs = 250\n",
    "cutoff_freqs = np.array([8,25])\n",
    "butter_sos = butter(N = filter_order, \n",
    "                    Wn = cutoff_freqs, \n",
    "                    btype = 'bandpass',\n",
    "                    analog = False,\n",
    "                    output = 'sos',\n",
    "                    fs = fs)\n",
    "\n",
    "subj_labels_2class = subj_labels[np.where(np.logical_or(class_labels == 1 , class_labels == 2))]\n",
    "class_labels_2class = class_labels[np.where(np.logical_or(class_labels == 1 , class_labels == 2))]\n",
    "\n",
    "M_res_2class = np.squeeze(M_res[np.where(np.logical_or(class_labels == 1 , class_labels == 2)),:,:])\n",
    "\n",
    "for i in range(len(class_labels_2class)):\n",
    "    M_res_2class[i,:,:] = sosfiltfilt(butter_sos, M_res_2class[i,:,:], axis = -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7677d",
   "metadata": {},
   "source": [
    "We then estimate CSPs by simultaneously diagonalizing the covariance matrices of both right/left MI classes. Our first eigenvectors will maximize the variance for class 1 and minimize the variance for class 2. The last eigenvectors will maximize the variance for class 2 and minimize for class 1. This estimation may look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "470fbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# Calculate CSP\n",
    "def myCSP(M_res,subj_labels, class_labels):\n",
    "    \n",
    "    # Get our list of unique subjects to \n",
    "    unique_subjects = np.unique(subj_labels)\n",
    "    \n",
    "    # Initialize our subject-weighted covariance for class 1 (left hand)\n",
    "    Cov_1 = np.zeros((M_res.shape[1],M_res.shape[1]))\n",
    "    # Initialize our subject-weighted covariance for class 2 (right hand)\n",
    "    Cov_2 = np.zeros((M_res.shape[1],M_res.shape[1]))\n",
    "    \n",
    "    # Get channel covariance matrix for both conditions           \n",
    "    Cov_1 = np.cov(np.squeeze(M_res[class_labels == 1,:,:].swapaxes(1,2).reshape(-1,M_res.shape[1])).T)\n",
    "    Cov_2 = np.cov(np.squeeze(M_res[class_labels == 2,:,:].swapaxes(1,2).reshape(-1,M_res.shape[1])).T)\n",
    "    \n",
    "    # Perform simultaneous diagonalization of both covariance matrices\n",
    "    evalues, evectors = eigh(Cov_1, Cov_1 + Cov_2)\n",
    "    # Sort vectors by value \n",
    "    evalues, evectors = evalues[np.argsort(evalues)], evectors[:,np.argsort(evalues)]\n",
    "    \n",
    "    # Return common spatial filters\n",
    "    return evectors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48957a23",
   "metadata": {},
   "source": [
    "We usually select a very small number of CSPs to add to the model. Let's see how the most discriminative filters for each class look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e211dab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_56856_row0_col0, #T_56856_row0_col1, #T_56856_row0_col2, #T_56856_row0_col4, #T_56856_row0_col7, #T_56856_row0_col8, #T_56856_row0_col11, #T_56856_row0_col15, #T_56856_row0_col16, #T_56856_row0_col17, #T_56856_row0_col18, #T_56856_row0_col19, #T_56856_row0_col21, #T_56856_row1_col3, #T_56856_row1_col5, #T_56856_row1_col6, #T_56856_row1_col9, #T_56856_row1_col10, #T_56856_row1_col12, #T_56856_row1_col13, #T_56856_row1_col14, #T_56856_row1_col20 {\n",
       "  background-color: #800000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_56856_row0_col3, #T_56856_row0_col5, #T_56856_row0_col6, #T_56856_row0_col9, #T_56856_row0_col10, #T_56856_row0_col12, #T_56856_row0_col13, #T_56856_row0_col14, #T_56856_row0_col20, #T_56856_row1_col0, #T_56856_row1_col1, #T_56856_row1_col2, #T_56856_row1_col4, #T_56856_row1_col7, #T_56856_row1_col8, #T_56856_row1_col11, #T_56856_row1_col15, #T_56856_row1_col16, #T_56856_row1_col17, #T_56856_row1_col18, #T_56856_row1_col19, #T_56856_row1_col21 {\n",
       "  background-color: #00004c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_56856\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56856_level0_col0\" class=\"col_heading level0 col0\" >Fz (1)</th>\n",
       "      <th id=\"T_56856_level0_col1\" class=\"col_heading level0 col1\" >2</th>\n",
       "      <th id=\"T_56856_level0_col2\" class=\"col_heading level0 col2\" >3</th>\n",
       "      <th id=\"T_56856_level0_col3\" class=\"col_heading level0 col3\" >4</th>\n",
       "      <th id=\"T_56856_level0_col4\" class=\"col_heading level0 col4\" >5</th>\n",
       "      <th id=\"T_56856_level0_col5\" class=\"col_heading level0 col5\" >6</th>\n",
       "      <th id=\"T_56856_level0_col6\" class=\"col_heading level0 col6\" >7</th>\n",
       "      <th id=\"T_56856_level0_col7\" class=\"col_heading level0 col7\" >C3 (8)</th>\n",
       "      <th id=\"T_56856_level0_col8\" class=\"col_heading level0 col8\" >9</th>\n",
       "      <th id=\"T_56856_level0_col9\" class=\"col_heading level0 col9\" >Cz (10)</th>\n",
       "      <th id=\"T_56856_level0_col10\" class=\"col_heading level0 col10\" >11</th>\n",
       "      <th id=\"T_56856_level0_col11\" class=\"col_heading level0 col11\" >C4 (12)</th>\n",
       "      <th id=\"T_56856_level0_col12\" class=\"col_heading level0 col12\" >13</th>\n",
       "      <th id=\"T_56856_level0_col13\" class=\"col_heading level0 col13\" >14</th>\n",
       "      <th id=\"T_56856_level0_col14\" class=\"col_heading level0 col14\" >15</th>\n",
       "      <th id=\"T_56856_level0_col15\" class=\"col_heading level0 col15\" >16</th>\n",
       "      <th id=\"T_56856_level0_col16\" class=\"col_heading level0 col16\" >17</th>\n",
       "      <th id=\"T_56856_level0_col17\" class=\"col_heading level0 col17\" >18</th>\n",
       "      <th id=\"T_56856_level0_col18\" class=\"col_heading level0 col18\" >19</th>\n",
       "      <th id=\"T_56856_level0_col19\" class=\"col_heading level0 col19\" >Pz (20)</th>\n",
       "      <th id=\"T_56856_level0_col20\" class=\"col_heading level0 col20\" >21</th>\n",
       "      <th id=\"T_56856_level0_col21\" class=\"col_heading level0 col21\" >22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >CSPs</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "      <th class=\"blank col11\" >&nbsp;</th>\n",
       "      <th class=\"blank col12\" >&nbsp;</th>\n",
       "      <th class=\"blank col13\" >&nbsp;</th>\n",
       "      <th class=\"blank col14\" >&nbsp;</th>\n",
       "      <th class=\"blank col15\" >&nbsp;</th>\n",
       "      <th class=\"blank col16\" >&nbsp;</th>\n",
       "      <th class=\"blank col17\" >&nbsp;</th>\n",
       "      <th class=\"blank col18\" >&nbsp;</th>\n",
       "      <th class=\"blank col19\" >&nbsp;</th>\n",
       "      <th class=\"blank col20\" >&nbsp;</th>\n",
       "      <th class=\"blank col21\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56856_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_56856_row0_col0\" class=\"data row0 col0\" >0.016514</td>\n",
       "      <td id=\"T_56856_row0_col1\" class=\"data row0 col1\" >-0.019027</td>\n",
       "      <td id=\"T_56856_row0_col2\" class=\"data row0 col2\" >0.034269</td>\n",
       "      <td id=\"T_56856_row0_col3\" class=\"data row0 col3\" >0.025976</td>\n",
       "      <td id=\"T_56856_row0_col4\" class=\"data row0 col4\" >0.036885</td>\n",
       "      <td id=\"T_56856_row0_col5\" class=\"data row0 col5\" >-0.093032</td>\n",
       "      <td id=\"T_56856_row0_col6\" class=\"data row0 col6\" >0.007868</td>\n",
       "      <td id=\"T_56856_row0_col7\" class=\"data row0 col7\" >-0.021807</td>\n",
       "      <td id=\"T_56856_row0_col8\" class=\"data row0 col8\" >0.091203</td>\n",
       "      <td id=\"T_56856_row0_col9\" class=\"data row0 col9\" >-0.067717</td>\n",
       "      <td id=\"T_56856_row0_col10\" class=\"data row0 col10\" >-0.291370</td>\n",
       "      <td id=\"T_56856_row0_col11\" class=\"data row0 col11\" >0.103689</td>\n",
       "      <td id=\"T_56856_row0_col12\" class=\"data row0 col12\" >-0.066289</td>\n",
       "      <td id=\"T_56856_row0_col13\" class=\"data row0 col13\" >-0.051078</td>\n",
       "      <td id=\"T_56856_row0_col14\" class=\"data row0 col14\" >0.004009</td>\n",
       "      <td id=\"T_56856_row0_col15\" class=\"data row0 col15\" >-0.018622</td>\n",
       "      <td id=\"T_56856_row0_col16\" class=\"data row0 col16\" >0.124376</td>\n",
       "      <td id=\"T_56856_row0_col17\" class=\"data row0 col17\" >0.330659</td>\n",
       "      <td id=\"T_56856_row0_col18\" class=\"data row0 col18\" >0.037850</td>\n",
       "      <td id=\"T_56856_row0_col19\" class=\"data row0 col19\" >0.072333</td>\n",
       "      <td id=\"T_56856_row0_col20\" class=\"data row0 col20\" >-0.271366</td>\n",
       "      <td id=\"T_56856_row0_col21\" class=\"data row0 col21\" >0.015994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_56856_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_56856_row1_col0\" class=\"data row1 col0\" >-0.006211</td>\n",
       "      <td id=\"T_56856_row1_col1\" class=\"data row1 col1\" >-0.044547</td>\n",
       "      <td id=\"T_56856_row1_col2\" class=\"data row1 col2\" >-0.026386</td>\n",
       "      <td id=\"T_56856_row1_col3\" class=\"data row1 col3\" >0.085034</td>\n",
       "      <td id=\"T_56856_row1_col4\" class=\"data row1 col4\" >0.018323</td>\n",
       "      <td id=\"T_56856_row1_col5\" class=\"data row1 col5\" >-0.076827</td>\n",
       "      <td id=\"T_56856_row1_col6\" class=\"data row1 col6\" >0.159807</td>\n",
       "      <td id=\"T_56856_row1_col7\" class=\"data row1 col7\" >-0.264062</td>\n",
       "      <td id=\"T_56856_row1_col8\" class=\"data row1 col8\" >-0.251056</td>\n",
       "      <td id=\"T_56856_row1_col9\" class=\"data row1 col9\" >0.065950</td>\n",
       "      <td id=\"T_56856_row1_col10\" class=\"data row1 col10\" >0.075254</td>\n",
       "      <td id=\"T_56856_row1_col11\" class=\"data row1 col11\" >0.066666</td>\n",
       "      <td id=\"T_56856_row1_col12\" class=\"data row1 col12\" >-0.011456</td>\n",
       "      <td id=\"T_56856_row1_col13\" class=\"data row1 col13\" >0.311037</td>\n",
       "      <td id=\"T_56856_row1_col14\" class=\"data row1 col14\" >0.101538</td>\n",
       "      <td id=\"T_56856_row1_col15\" class=\"data row1 col15\" >-0.045784</td>\n",
       "      <td id=\"T_56856_row1_col16\" class=\"data row1 col16\" >-0.074915</td>\n",
       "      <td id=\"T_56856_row1_col17\" class=\"data row1 col17\" >-0.051794</td>\n",
       "      <td id=\"T_56856_row1_col18\" class=\"data row1 col18\" >-0.090834</td>\n",
       "      <td id=\"T_56856_row1_col19\" class=\"data row1 col19\" >0.001028</td>\n",
       "      <td id=\"T_56856_row1_col20\" class=\"data row1 col20\" >0.072617</td>\n",
       "      <td id=\"T_56856_row1_col21\" class=\"data row1 col21\" >-0.014629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24b55ec04f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the number of filters to choose that maximize each class (n_filters = 2*m)\n",
    "m = 1\n",
    "\n",
    "# Get all possible CSPs\n",
    "V = myCSP(M_res_2class,subj_labels_2class,class_labels_2class)\n",
    "\n",
    "# Choose only the best m for each class\n",
    "CSP = np.concatenate((V[:,:m], V[:,V.shape[1]-m:]),axis= 1)\n",
    "\n",
    "\n",
    "# Get a table with the most important channel weights for each of the 3 most important components\n",
    "best_evals_df = pd.DataFrame(CSP.T,columns = ch_names)\n",
    "best_evals_df.index.name = 'CSPs'\n",
    "# Add an heatmap effect to the table for easier visualization\n",
    "best_evals_df.style.background_gradient(cmap ='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd19534e",
   "metadata": {},
   "source": [
    "From analysing the table we have:\n",
    "\n",
    "- **CSP0**: Mostly dipoles at right parietal areas\n",
    "- **CSP1** - Mostly dipoles at left central areas\n",
    "\n",
    "Similarly to what we have done for PCA, let's integrate CSP into our validation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "582c47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateSimpleModels_CSP(subj_labels,M_res,class_labels,model,m):\n",
    "    # Get our list of unique subjects to \n",
    "    unique_subjects = np.unique(subj_labels)\n",
    "    \n",
    "    # Initialize our list of test accuracy scores for every subject \n",
    "    test_scores = []\n",
    "    \n",
    "    # Perfrom cross-validation leaving always a different subject out\n",
    "    for subject in unique_subjects:\n",
    "        \n",
    "        # Calculate our spatial filters from the training dataset\n",
    "        V = myCSP(M_res[subj_labels != subject,:,:],subj_labels[subj_labels != subject],class_labels_2class[subj_labels != subject])\n",
    "        \n",
    "        # Choose only the best m for each class\n",
    "        CSP = np.concatenate((V[:,:m], V[:,V.shape[1]-m:]),axis= 1)\n",
    "        \n",
    "        # Get our variance features from the CSP-projected data\n",
    "        X = np.zeros((len(subj_labels),2*m))\n",
    "        for i in range(M_res.shape[0]):\n",
    "            X[i,:] = np.var(M_res[i,:,:].T @ CSP,axis = 0) / np.sum(np.var(M_res[i,:,:].T @ CSP,axis = 0))\n",
    "        \n",
    "        # Get our training data and MI class labels\n",
    "        X_train = X[subj_labels != subject,:]\n",
    "        y_train = class_labels[subj_labels != subject]\n",
    "        \n",
    "        # Fit our model to the training data\n",
    "        classifier = clone(model)\n",
    "        classifier.fit(X_train,y_train)\n",
    "        \n",
    "        # Get training accuracy (training fit)\n",
    "        train_fit = classifier.score(X_train,y_train)\n",
    "        \n",
    "        # Get test data and labels\n",
    "        X_test  = X[subj_labels == subject,:]\n",
    "        y_test  = class_labels[subj_labels == subject]\n",
    "        \n",
    "        # Get test accuracy\n",
    "        test_fit = classifier.score(X_test,y_test)\n",
    "        # Append it to our test score list\n",
    "        test_scores.append(test_fit)\n",
    "\n",
    "        print('Subject ' +str(subject)[:4]+' test acc: ' +str(test_fit)[:4]+ ' (train score: '+str(train_fit)[:4]+')')\n",
    "    \n",
    "    print('Average model accuracy: '+str(np.mean(test_scores))[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcedfb03",
   "metadata": {},
   "source": [
    "And now lets see how do we do using a linear model. Remember since we are working with only 2 classes for this demonstration, chance level is at 0.5. You can change the number of filters and see how the classification changes too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ebb0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject A01 test acc: 0.70 (train score: 0.69)\n",
      "Subject A02 test acc: 0.52 (train score: 0.71)\n",
      "Subject A03 test acc: 0.87 (train score: 0.66)\n",
      "Subject A04 test acc: 0.69 (train score: 0.69)\n",
      "Subject A05 test acc: 0.53 (train score: 0.71)\n",
      "Subject A06 test acc: 0.52 (train score: 0.69)\n",
      "Subject A07 test acc: 0.60 (train score: 0.70)\n",
      "Subject A08 test acc: 0.93 (train score: 0.64)\n",
      "Subject A09 test acc: 0.70 (train score: 0.72)\n",
      "Average model accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Choose the number of filters that maximize the variance of each class to use\n",
    "m = 3\n",
    "\n",
    "classifier_linear = LogisticRegression(random_state = 0,\n",
    "                                solver = 'liblinear',\n",
    "                                penalty = 'l2',\n",
    "                                C = 100) \n",
    "\n",
    "validateSimpleModels_CSP(subj_labels_2class,M_res_2class,class_labels_2class,classifier_linear,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311756b3",
   "metadata": {},
   "source": [
    "### Next up: Deep Learning\n",
    "While we are getting accuracies that are better than chance we are still far away from state-of-art performances. In the next notebook, we will explore how we can use more advanced methods to test more complex and plausible ideas regarding useful information extraction from our EEG data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
